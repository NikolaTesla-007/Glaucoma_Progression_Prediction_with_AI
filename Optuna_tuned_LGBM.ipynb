{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0gCeDAKqlbx",
        "outputId": "5ae20986-852f-449d-f87f-7ce2f8d8d0ae"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.12.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4HzYWGia4mO",
        "outputId": "30181b00-88a3-490a-f464-4e7bd4fd261e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#import required packages\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from numpy import mean\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve\n",
        "from lightgbm import LGBMClassifier\n",
        "import optuna\n",
        "from collections import defaultdict\n",
        "RANDOM_SEED = 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_tuple(tup,i,rev = False):\n",
        "  '''given a tuple, sorts it based on index i'''\n",
        "  for x in tup:\n",
        "    assert isinstance(x[i], float)\n",
        "  tup.sort(key = lambda x: x[i],reverse = rev)\n",
        "  return tup"
      ],
      "metadata": {
        "id": "EmW6MmytZvnl"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dummies(df,cols):\n",
        "  '''create one-hot encoding of given columns'''\n",
        "  assert isinstance(cols, list)\n",
        "  assert isinstance(df, pd.DataFrame)\n",
        "  df = pd.get_dummies(df, columns=[col for col in ['genderCAP','racecodeCAP']])\n",
        "  return df"
      ],
      "metadata": {
        "id": "VsEVz6OJZvqd"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "G-4ajFcylKOZ"
      },
      "outputs": [],
      "source": [
        "def normalize_cols(df,cols_to_norm):\n",
        "  '''normalise the given columns'''\n",
        "  assert isinstance(df, pd.DataFrame)\n",
        "  assert isinstance(cols_to_norm, list)\n",
        "  df[cols_to_norm]= df[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max()-x.min()))\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_consecutive_rnfl(model):\n",
        "  '''removes consecutive rnfl features as they are highly correlated'''\n",
        "  assert isinstance(model, list)\n",
        "  for feat in model:\n",
        "    if 'rnfl_sec' in feat:\n",
        "      number = feat.split('_')[2]\n",
        "\n",
        "      # define the neighboring rnfl sectors\n",
        "      plus1 = 'rnfl_sec_'+str(int(number)+1)+'_slope'\n",
        "      minus1 = 'rnfl_sec_'+str(int(number)-1)+'_slope'\n",
        "      if plus1 in model:\n",
        "        model.remove(plus1)\n",
        "      if minus1 in model:\n",
        "        model.remove(minus1)\n",
        "  return model"
      ],
      "metadata": {
        "id": "zKsgU2WvpA-J"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_consecutive_gcc(model):\n",
        "  '''removes consecutive gcc features as they are highly correlated'''\n",
        "  assert isinstance(model, list)\n",
        "  for feat in model:\n",
        "    if 'gcc' in feat:\n",
        "      number = feat.split('_')[0][-2:]\n",
        "\n",
        "      # define the neighboring gcc sectors\n",
        "      plus1 = 'mean'+str(int(number)+1)+'_gcc_slope'\n",
        "      minus1 = 'mean'+str(int(number)+10)+'_gcc_slope'\n",
        "      plus2 = 'mean'+str(int(number)-1)+'_gcc_slope'\n",
        "      minus2 = 'mean'+str(int(number)-10)+'_gcc_slope'\n",
        "      if plus1 in model:\n",
        "        model.remove(plus1)\n",
        "      if minus1 in model:\n",
        "        model.remove(minus1)\n",
        "      if plus2 in model:\n",
        "        model.remove(plus2)\n",
        "      if minus2 in model:\n",
        "        model.remove(minus2)\n",
        "  return model"
      ],
      "metadata": {
        "id": "5EZlkK7RZ8qM"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "DnFqzpjgszSt"
      },
      "outputs": [],
      "source": [
        "def get_sorted_features(feat_df,group,y_var):\n",
        "  '''sorts the features by importance (descending order),\n",
        "     basing on their ability to discriminate the target\n",
        "     variable, uses Kolmogorov-Smirov test'''\n",
        "  assert isinstance(feat_df, pd.DataFrame)\n",
        "  assert isinstance(y_var, str)\n",
        "\n",
        "  # split data into positive and negative examples\n",
        "  eve0 = feat_df[feat_df[y_var]==0]\n",
        "  eve1 = feat_df[feat_df[y_var]==1]\n",
        "  ks_tup_list = []\n",
        "\n",
        "  for col in feat_df.columns:\n",
        "    x = eve0[col]\n",
        "    y = eve1[col]\n",
        "    #for each feature, save the KS test stat\n",
        "    ks_tup_list.append((col,stats.ks_2samp(x, y)[1]))\n",
        "\n",
        "  # sort the features using their KS test stat\n",
        "  ks_sorted = sort_tuple(ks_tup_list,1)\n",
        "  best_feat_list = list(list(zip(*ks_sorted))[0])\n",
        "  best_feat_list.remove(y_var)\n",
        "  return best_feat_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_correlated_vars(list_of_models):\n",
        "  '''removes correlated variables in the candidate model,\n",
        "     calls both helper functions remove_consecutive_rnfl\n",
        "     and remove_consecutive_gcc'''\n",
        "  assert isinstance(list_of_models, list)\n",
        "  new = []\n",
        "  for model in list_of_models:\n",
        "    assert isinstance(model, list)\n",
        "    # for each candidate model, remove the neighboring gcc and rnfl features\n",
        "    model = remove_consecutive_rnfl(model)\n",
        "    model = remove_consecutive_gcc(model)\n",
        "    if model not in new:\n",
        "      new.append(model)\n",
        "  return new"
      ],
      "metadata": {
        "id": "vksX0YYAaI3v"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "P2D8fQa4FFLX"
      },
      "outputs": [],
      "source": [
        "def get_best_clin(feat_df,group,y_var):\n",
        "  '''gets the best clinical features using KS test'''\n",
        "  assert isinstance(feat_df, pd.DataFrame)\n",
        "  assert isinstance(y_var, str)\n",
        "  eve0 = feat_df[feat_df[y_var]==0]\n",
        "  eve1 = feat_df[feat_df[y_var]==1]\n",
        "  best_feat_list = []\n",
        "  ks_tup_list = []\n",
        "  for col in feat_df.columns:\n",
        "    x = eve0[col]\n",
        "    y = eve1[col]\n",
        "    ks_tup_list.append((col,stats.ks_2samp(x, y)[1]))\n",
        "\n",
        "  ks_sorted = sort_tuple(ks_tup_list,1)\n",
        "  best_feat_list = list(list(zip(*ks_sorted))[0])\n",
        "  best_feat_list.remove(y_var)\n",
        "  return best_feat_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_list_of_models(min_non_clinical_features, clinical_features):\n",
        "  '''splits the features into clinical and non-clinical (based on the name).\n",
        "  then generates candidate models, each candidate model has 5 clinical features\n",
        "  and at least x non-clinical features'''\n",
        "  assert isinstance(min_non_clinical_features, int)\n",
        "  assert isinstance(clinical_features, int)\n",
        "  global trains, vals, test\n",
        "  train_df = trains[0]\n",
        "  test_df = test\n",
        "  val_df = vals[0]\n",
        "\n",
        "  gcc_rnfl,clin = split_features(train_df,val_df,'event')\n",
        "  list_of_models = []\n",
        "  base = min_non_clinical_features\n",
        "  for j in [1,2,3]:\n",
        "    a,b,c,d,e = base, base+2,base+4,base+6, base+8\n",
        "    if j==1:\n",
        "      model = gcc_rnfl[:a]+clin[:clinical_features]\n",
        "    if j==2:\n",
        "      model = gcc_rnfl[:b]+clin[:clinical_features]\n",
        "    if j==3:\n",
        "      model = gcc_rnfl[:c]+clin[:clinical_features]\n",
        "    if j==4:\n",
        "      model = gcc_rnfl[:d]+clin[:clinical_features]\n",
        "    if j==5:\n",
        "      model = gcc_rnfl[:e]+clin[:clinical_features]\n",
        "\n",
        "    list_of_models.append(model)\n",
        "  return list_of_models"
      ],
      "metadata": {
        "id": "znabSrS5TSKn"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "31B6sLrJ6SrD"
      },
      "outputs": [],
      "source": [
        "def split_features(train_df,val_df,y_var):\n",
        "  '''takes the train and val dfs, merges them and returns clinical and\n",
        "  non-clinical features as lists (in descending order of importance)'''\n",
        "  assert isinstance(train_df, pd.DataFrame)\n",
        "  assert isinstance(val_df, pd.DataFrame)\n",
        "  assert isinstance(y_var, str)\n",
        "  feat_df = pd.concat([train_df,val_df])\n",
        "  non_features = [col for col in feat_df.columns if 'rnflmean' in col]\n",
        "  if y_var=='event':\n",
        "    non_features += ['eye_id','sphere_equiv.1','PatientID','prog_all','prog_trend','prog_plr']\n",
        "  elif y_var == 'prog_trend':\n",
        "    non_features += ['eye_id','sphere_equiv.1','PatientID','prog_all','event','prog_plr']\n",
        "  features = [col for col in feat_df.columns if col not in non_features]\n",
        "  gcc = [col for col in features if 'gcc' in col]\n",
        "  rnfl = [col for col in features if 'rnfl' in col]\n",
        "  clin = ['iopmeanfu','iopundil_meas','genderCAP_Male','racecodeCAP_Black or African American',\\\n",
        "          'iopmaxfu','iopminfu','sphere_equiv','diabetesCAP','systolic','diastolic','md_24','psd_24']\n",
        "  group = gcc+rnfl\n",
        "  group.append(y_var)\n",
        "  df = feat_df[group]\n",
        "  group_best = get_sorted_features(df,group,y_var)\n",
        "  clin.append(y_var)\n",
        "  df2 = feat_df[clin]\n",
        "  clin = get_best_clin(df2,clin,y_var)\n",
        "  return group_best,clin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_test_final_model(final_feat, final_params):\n",
        "  '''takes the best features and best hyper-parameters (given by the val set),\n",
        "  then retrains the model on the combined train and val set,\n",
        "  then performs testing on the test set'''\n",
        "  assert isinstance(final_feat, list)\n",
        "\n",
        "  global trains, vals, test\n",
        "\n",
        "  train_df = trains[0]\n",
        "  test_df = test\n",
        "  val_df = vals[0]\n",
        "\n",
        "  train_df = normalize_cols(train_df,final_feat)\n",
        "  test_df = normalize_cols(test_df,final_feat)\n",
        "  val_df = normalize_cols(val_df,final_feat)\n",
        "\n",
        "  x_train,y_train = train_df[final_feat],train_df['event']\n",
        "  x_val,y_val = val_df[final_feat],val_df['event']\n",
        "  x_test,y_test = test_df[final_feat],test_df['event']\n",
        "\n",
        "  x_train_val,y_train_val = pd.concat([x_train,x_val],ignore_index=True),pd.concat([y_train,y_val])\n",
        "  model = LGBMClassifier(**final_params)#,is_unbalance=True\n",
        "\n",
        "  model.fit(x_train_val, y_train_val)\n",
        "  pred_probs = model.predict_proba(x_test)\n",
        "  auc = metrics.roc_auc_score(y_test, pred_probs[:,1])\n",
        "  fpr,tpr, _ = roc_curve(y_test, pred_probs[:,1])\n",
        "  roc_data = list(zip(fpr,tpr))\n",
        "\n",
        "  test_df['y_hat'] = pred_probs[:,1]\n",
        "  boots = test_df[['PatientID','event','y_hat','eye_id']]\n",
        "  boots.rename(columns={'event': 'y_true', 'PatientID': 'patient_ID','eye_id':'eye_ID'}, inplace=True)\n",
        "\n",
        "  return (auc,roc_data,boots)"
      ],
      "metadata": {
        "id": "jANthQlc8IHV"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optuna_model(min_non_clinical_features, clinical_features):\n",
        "  '''for each candidate model, get the best hyperparameters and\n",
        "  performance on validation set'''\n",
        "  assert isinstance(min_non_clinical_features,  int)\n",
        "  assert isinstance(clinical_features, int)\n",
        "  list_of_models = get_list_of_models(min_non_clinical_features, clinical_features)\n",
        "  list_of_models = remove_correlated_vars(list_of_models)\n",
        "\n",
        "  all_results = []\n",
        "  for candidate_model in list_of_models:\n",
        "    cw = {0:0.3,1:0.7}\n",
        "    candi_res = get_res(candidate_model)\n",
        "    all_results.append(candi_res)\n",
        "\n",
        "  return all_results\n"
      ],
      "metadata": {
        "id": "gNlZmGIMUTAi"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_save_data(path):\n",
        "  '''load all the required csvs and save them in global variables,\n",
        "  this helps avoid repeated read calls'''\n",
        "  assert os.path.exists(path)\n",
        "  global trains, vals, test\n",
        "\n",
        "  test_df = pd.read_csv(path + 'event_test'+'.csv')\n",
        "  test_df = test_df.loc[:, ~test_df.columns.str.contains('^Unnamed')]\n",
        "  test = test_df\n",
        "  for i in range(4):\n",
        "      train_df = pd.read_csv(path + 'event_train_'+str(i+1)+'.csv' )\n",
        "      val_df = pd.read_csv(path + 'event_val_'+str(i+1)+'.csv' )\n",
        "      train_df = train_df.loc[:, ~train_df.columns.str.contains('^Unnamed')]\n",
        "      val_df = val_df.loc[:, ~val_df.columns.str.contains('^Unnamed')]\n",
        "      trains.append(train_df)\n",
        "      vals.append(val_df)"
      ],
      "metadata": {
        "id": "7KJ-jtRx54Bm"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_res(all_feat):\n",
        "  '''runs the experiments on hyperparameters using optuna, records and returns\n",
        "  the best validation auc and the corresponding hyperparmeters for a\n",
        "  candidate model. The validation auc is deteremined by 4-fold cross val'''\n",
        "  assert isinstance(final_feat, list)\n",
        "  global trains, vals, test\n",
        "\n",
        "  all_feat = all_feat\n",
        "  def objective(trial):\n",
        "    n_estimators_hp = trial.suggest_int('n_estimators', 50,500, step = 50)\n",
        "    max_depth_hp = trial.suggest_int('max_depth', 2,7)\n",
        "    min_child_samples_hp = trial.suggest_int('min_child_samples', 10, 50, step = 10)\n",
        "    num_leaves_hp = trial.suggest_int('num_leaves', 2, 8)\n",
        "    learning_rate_hp = trial.suggest_float('learning_rate',1e-4,10)\n",
        "    max_bin_hp = trial.suggest_int('max_bin',5,10)\n",
        "    lambda_l2_hp = trial.suggest_float('reg_lambda',0,2)\n",
        "    bagging_fraction_hp = trial.suggest_float('subsample',1e-4,1)\n",
        "\n",
        "    roc_val_li = []\n",
        "\n",
        "    for i in range(4):\n",
        "          train_df = trains[i]\n",
        "          test_df = test\n",
        "          val_df = vals[i]\n",
        "\n",
        "          train_df = normalize_cols(train_df,all_feat)\n",
        "          test_df = normalize_cols(test_df,all_feat)\n",
        "          val_df = normalize_cols(val_df,all_feat)\n",
        "\n",
        "          x_train,y_train = train_df[all_feat],train_df['event']\n",
        "          x_val,y_val = val_df[all_feat],val_df['event']\n",
        "          x_test,y_test = test_df[all_feat],test_df['event']\n",
        "\n",
        "          x_train_val,y_train_val = pd.concat([x_train,x_val],ignore_index=True),pd.concat([y_train,y_val])\n",
        "          cw = {0:0.3,1:0.7}\n",
        "          model = LGBMClassifier(n_estimators = n_estimators_hp,\n",
        "                                max_depth = max_depth_hp,\n",
        "                                min_child_samples = min_child_samples_hp,\n",
        "                                num_leaves = num_leaves_hp,\n",
        "                                learning_rate = learning_rate_hp,\n",
        "                                max_bin = max_bin_hp,\n",
        "                                reg_lambda = lambda_l2_hp,\n",
        "                                subsample = bagging_fraction_hp,\n",
        "                                random_state = 0,is_unbalance=True)#False, class_weight = cw\n",
        "\n",
        "          model.fit(x_train, y_train)\n",
        "          pred_probs = model.predict_proba(x_val)\n",
        "\n",
        "          roc_val_li.append(metrics.roc_auc_score(y_val, pred_probs[:,1]))\n",
        "\n",
        "    return sum(roc_val_li)/len(roc_val_li)\n",
        "\n",
        "  model_res = defaultdict(dict)\n",
        "  model_res['features'] = all_feat\n",
        "  model_res['name'] = 'test set'\n",
        "\n",
        "  optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
        "\n",
        "  study = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=2022))\n",
        "  study.optimize(objective, n_trials=50)\n",
        "\n",
        "  model_res['best_para'] = study.best_trial.params\n",
        "  model_res['avg_val_auc'] = study.best_trial.value\n",
        "\n",
        "  return model_res"
      ],
      "metadata": {
        "id": "kRjxYIZydcOs"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_model_to_file(best_model,outpath,outfile):\n",
        "  '''writes the final model to a text file'''\n",
        "  assert isinstance(best_model, list)\n",
        "  assert isinstance(outfile, str)\n",
        "  assert os.path.exists(outpath)\n",
        "  file_path = '/content/drive/Shareddrives/Glaucoma_features/k198/train_val_test_splits/'+outfile\n",
        "  if os.path.exists(file_path):\n",
        "    with open(file_path, 'a') as file:\n",
        "        file.write(str(best_model) + '\\n')\n",
        "  else:\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(str(best_model) + '\\n')"
      ],
      "metadata": {
        "id": "hxStJJVQBWBR"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_final_model_for_test_set(list_of_all_results):\n",
        "  '''determines the best features and the corresponding hyperparameters,\n",
        "  basing on the average validation auc'''\n",
        "  assert isinstance(list_of_all_results, list)\n",
        "  key = \"avg_val_auc\"\n",
        "\n",
        "  # Finding the dictionary with the highest value for the given key\n",
        "  best_for_given_subset = max(list_of_all_results, key=lambda x: x.get(key, 0))\n",
        "  print(best_for_given_subset['best_para'])\n",
        "  return best_for_given_subset['features'], best_for_given_subset['best_para']\n"
      ],
      "metadata": {
        "id": "dbavsix6whsG"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "trains = []\n",
        "vals = []\n",
        "test = None\n",
        "\n",
        "# set the min. number of non-clinical features\n",
        "min_non_clinical_features = 13\n",
        "clinical_features = 5\n",
        "aucs_m = []\n",
        "\n",
        "# specify input and output paths\n",
        "output_path = '/content/drive/Shareddrives/Glaucoma_features/k198/Raghu_Optuna/'\n",
        "input_path = '/content/drive/Shareddrives/Glaucoma_features/k198/train_val_test_splits/'\n",
        "\n",
        "# cache\n",
        "process_and_save_data(input_path)\n",
        "list_of_set_results = get_optuna_model(min_non_clinical_features, clinical_features)\n",
        "final_feat, final_params = get_final_model_for_test_set(list_of_set_results)\n",
        "auc_i, roc_i, boots = train_and_test_final_model(final_feat, final_params)\n",
        "\n",
        "# save the results\n",
        "write_model_to_file(final_feat,output_path,outfile='LGBM.txt')\n",
        "boots.to_csv(output_path+'boots'+'.csv')\n",
        "aucs_m.append(auc_i)\n",
        "print(aucs_m)\n",
        "\n"
      ],
      "metadata": {
        "id": "81KWkpNOa6k6"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aucs_m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMIP8QqJTUJU",
        "outputId": "66fed4ee-490b-4025-ab49-b3347efcc4f9"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7875]"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYyTPJHPWKYW"
      },
      "execution_count": 168,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}